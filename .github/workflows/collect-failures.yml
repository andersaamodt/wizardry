name: Collect test failures

# Collects failure outputs and makes them visible to Copilot via:
# 1. PR description (updated automatically with "## üîç Latest Test Failures" section)
# 2. Job summaries (visible in workflow run UI)
# 3. Workflow logs (sequential output for easy review)
#
# For AI agents: When a user asks you to fix test failures:
# 1. Run: ./.github/read-test-failures 783  (replace 783 with actual PR number)
#    This fetches the PR description and extracts the failures section
# 2. Read the output to see what's failing
# 3. Fix the issues and commit your changes
# 4. The workflow will update the PR description automatically on next run
#
# The read-test-failures script fetches the PR description via GitHub API,
# allowing you to see failures IMMEDIATELY in the current session without any
# files being committed to the repository.

on:
  pull_request:
    types: [opened, synchronize, reopened]

# Cancel previous runs when a new commit is pushed
concurrency:
  group: collect-failures-${{ github.event.pull_request.number }}
  cancel-in-progress: true

permissions:
  contents: read
  actions: read
  pull-requests: write
  checks: write

jobs:
  collect-failures:
    name: Collect workflow failures
    runs-on: ubuntu-latest
    timeout-minutes: 60  # Maximum 1 hour monitoring

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Monitor workflows and collect failures
        id: collect
        shell: bash
        env:
          GH_TOKEN: ${{ github.token }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          COMMIT_SHA: ${{ github.event.pull_request.head.sha }}
        run: |
          set -euo pipefail

          echo "========================================================================"
          echo " WORKFLOW FAILURE COLLECTION"
          echo "========================================================================"
          echo "PR Number: $PR_NUMBER"
          echo "Commit SHA: $COMMIT_SHA"
          echo ""

          # Track which workflows we've already reported (using file-based storage)
          mkdir -p /tmp/reported_runs
          
          # Initialize failure/success summary files for PR description
          failure_summary_file="/tmp/failure_summary.txt"
          success_summary_file="/tmp/success_summary.txt"
          : > "$failure_summary_file"
          : > "$success_summary_file"

          # Workflows to monitor
          workflows=(
            "139-137 Ubuntu Xtrace validate-spells pocket-dimension"
            "139-138 Ubuntu Xtrace validate-spells wizard-eyes"
            "139-139 Ubuntu Xtrace validate-spells spellbook-store"
            "139-140 Ubuntu Xtrace validate-spells imps format-duration"
            "139-141 Ubuntu Xtrace spell-levels list"
            "139-142 Ubuntu Xtrace pocket dimension call"
            "139-143 Ubuntu Xtrace source pocket gloss only"
            "139-144 Ubuntu Xtrace banish level 8 only"
            "139-145 Ubuntu Xtrace validate-spells level8 spells"
            "139-146 Ubuntu Xtrace validate-spells level8 imps"
          )
          
          # Total number of workflows we're monitoring
          total_workflows=${#workflows[@]}

          # Function to extract test summary from logs
          extract_test_summary() {
            local logfile=$1
            # Keep the "Process completed/exited" line but remove everything after it
            local cleaned_log="/tmp/cleaned_$$.txt"
            sed '/Process \(exited\|completed\)/q' "$logfile" > "$cleaned_log"
            
            # Extract from "Summary" heading line to the end of file
            if grep -q "^Summary$" "$cleaned_log"; then
              sed -n '/^Summary$/,$p' "$cleaned_log" | head -500
            elif grep -q "=== Lint Results ===" "$cleaned_log"; then
              # Lint-magic format: extract from "=== Lint Results ===" to end
              # Limit to 500 lines to prevent PR description overflow
              sed -n '/=== Lint Results ===/,$p' "$cleaned_log" | head -500
            elif grep -q "=== Test Summary ===" "$cleaned_log"; then
              # Fallback to old format
              sed -n '/=== Test Summary ===/,/^===/p' "$cleaned_log" | head -n -1 | head -500
            else
              # If no test summary, show more of the tail (tests are likely incomplete/running)
              # Show last 200 lines to capture the complete test tail
              tail -200 "$cleaned_log"
            fi
            
            rm -f "$cleaned_log"
          }

          # Function to extract failed step from logs
          extract_failed_step() {
            local logfile=$1
            local job_name=$2
            local workflow_name=$3

            # Keep the "Process completed/exited" line but remove everything after it from the entire log
            local cleaned_log="/tmp/cleaned_$$.txt"
            sed '/Process \(exited\|completed\)/q' "$logfile" > "$cleaned_log"

            # Check for early failure (workflow failed before tests ran)
            # Look for actual error indicators, not test messages that mention errors
            # Skip this check if we see test output (PASS/FAIL lines with timestamps)
            if ! grep -qE "[[:space:]](PASS|FAIL)[[:space:]]" "$cleaned_log" && \
               grep -qE "not found|No such file|Permission denied|cannot access" "$cleaned_log"; then
              # Extract the error and surrounding context (this is an early failure)
              grep -E -B 10 -A 2 "not found|No such file|Permission denied|cannot access" "$cleaned_log" | head -50
              rm -f "$cleaned_log"
              return
            fi

            # For unit tests, extract test summary
            if echo "$workflow_name" | grep -qi "unit test"; then
              extract_test_summary "$logfile"
              rm -f "$cleaned_log"
              return
            fi

            # For demonstrate wizardry, extract demo-magic output tail (where failures appear)
            if echo "$workflow_name" | grep -qi "demonstrate"; then
              # Demo-magic shows failures at the end, so extract the last part of output
              # Look for error indicators or just show the tail
              if grep -qE "error|failed|FAIL" "$cleaned_log"; then
                # Show errors and context
                grep -iE -B 5 -A 2 "error|failed|FAIL" "$cleaned_log" | tail -50
              else
                # Show last part of demo-magic output
                tail -30 "$cleaned_log"
              fi
              rm -f "$cleaned_log"
              return
            fi

            # For POSIX/linting workflows, show summary section
            if echo "$workflow_name" | grep -qi "POSIX\|linting\|style"; then
              # Use standard test summary extraction for lint-magic
              extract_test_summary "$logfile"
              rm -f "$cleaned_log"
              return
            fi

            # For other workflows, find the failing step in cleaned log
            if grep -q "##\[error\]" "$cleaned_log"; then
              # Extract error lines and surrounding context
              grep -B 5 -A 10 "##\[error\]" "$cleaned_log" | head -100
            elif grep -qi "FAIL\|ERROR" "$cleaned_log"; then
              # Extract failure lines
              grep -i -B 3 -A 3 "FAIL\|ERROR" "$cleaned_log" | head -100
            else
              # Last resort: show last part of cleaned log
              tail -50 "$cleaned_log"
            fi
            
            rm -f "$cleaned_log"
          }

          # Function to extract success details from logs
          extract_success_details() {
            local logfile=$1
            local cleaned_log="/tmp/cleaned_success_$$.txt"
            sed '/Process \(exited\|completed\)/q' "$logfile" > "$cleaned_log"
            tail -120 "$cleaned_log"
            rm -f "$cleaned_log"
          }

          # Function to update PR description with current failures
          update_pr_description() {
            local pr_number="$PR_NUMBER"
            local failure_summary_content
            local success_summary_content
            local completed_count
            
            # Count how many workflows are completed
            completed_count=$(ls -1 /tmp/reported_runs 2>/dev/null | wc -l)
            
            if [ -s "$failure_summary_file" ]; then
              failure_summary_content=$(cat "$failure_summary_file")
            else
              failure_summary_content=""
            fi
            
            if [ -s "$success_summary_file" ]; then
              success_summary_content=$(cat "$success_summary_file")
            else
              success_summary_content=""
            fi
            
            # Determine status message
            local status_message
            if [ "$completed_count" -ge "$total_workflows" ]; then
              # All workflows completed
              if [ -n "$failure_summary_content" ]; then
                status_message=""  # Failures are shown, no need for extra message
              else
                status_message="‚úÖ All tests passing!"
              fi
            else
              # Still running
              if [ -n "$failure_summary_content" ]; then
                status_message="‚ö†Ô∏è Tests are still running. More errors may appear."
              else
                status_message="‚è≥ Tests are running. Errors will be copied here by the collect-failures workflow."
              fi
            fi
            
            # Call GitHub API to update PR description
            gh api --method PATCH "/repos/${{ github.repository }}/pulls/${pr_number}" \
              -f body="$(gh api "/repos/${{ github.repository }}/pulls/${pr_number}" --jq '.body' | \
                sed '/## üîç Latest Test Failures/,/<!-- test-failures-end -->/d' | \
                sed 's/---$//' | sed '/^$/N;/^\n$/D' && \
                echo "" && echo "---" && echo "" && \
                echo "## üîç Latest Test Failures" && echo "" && \
                echo "**Updated:** $(date -u '+%Y-%m-%d %H:%M:%S') UTC" && echo "" && \
                if [ -n "$failure_summary_content" ]; then cat "$failure_summary_file"; fi && \
                echo "" && \
                echo "## ‚úÖ Latest Test Successes" && echo "" && \
                if [ -n "$success_summary_content" ]; then cat "$success_summary_file"; else echo "_No successful workflows recorded yet._"; fi && \
                if [ -n "$status_message" ]; then echo ""; echo "$status_message"; fi && \
                echo "" && echo "<!-- test-failures-end -->")" \
              > /dev/null 2>&1 || echo "‚ö†Ô∏è Could not update PR description"
          }

          # Function to process a completed workflow run
          process_workflow_run() {
            local run_id=$1
            local workflow_name=$2
            local conclusion=$3

            # Skip if already reported
            if [ -f "/tmp/reported_runs/$run_id" ]; then
              return
            fi

            touch "/tmp/reported_runs/$run_id"

            echo "----------------------------------------"
            echo "Workflow: $workflow_name"
            echo "Run ID: $run_id"
            echo "Status: $conclusion"
            echo ""

            if [ "$conclusion" = "success" ]; then
              echo "‚úÖ Passed"
              echo ""
              {
                echo ""
                echo "### ‚úÖ $workflow_name"
                echo ""
              } >> "$success_summary_file"

              if gh api "/repos/${{ github.repository }}/actions/runs/${run_id}/jobs" \
                > /tmp/jobs_${run_id}.json 2>&1; then
                jq -r '.jobs[] | "\(.id)|\(.name)"' /tmp/jobs_${run_id}.json | \
                while IFS='|' read -r job_id job_name; do
                  if gh api "/repos/${{ github.repository }}/actions/jobs/${job_id}/logs" \
                    > /tmp/log_${job_id}.txt 2>&1; then
                    success_text=$(extract_success_details "/tmp/log_${job_id}.txt")
                    {
                      echo "**Job:** $job_name"
                      echo '```'
                      echo "$success_text"
                      echo '```'
                      echo ""
                    } >> "$success_summary_file"
                  else
                    {
                      echo "**Job:** $job_name"
                      echo ""
                      echo "_Unable to download job logs._"
                      echo ""
                    } >> "$success_summary_file"
                  fi
                  rm -f /tmp/log_${job_id}.txt
                done
                rm -f /tmp/jobs_${run_id}.json
              fi
              # Update PR description after each completion
              update_pr_description
              return
            fi

            if [ "$conclusion" != "failure" ]; then
              echo "Status: $conclusion (skipped)"
              echo ""
              return
            fi

            echo "‚ùå FAILED - extracting error details..."
            echo ""

            # Get failed jobs
            if ! gh api "/repos/${{ github.repository }}/actions/runs/${run_id}/jobs" \
              > /tmp/jobs_${run_id}.json 2>&1; then
              {
                echo '```'
                echo "Unable to download job list for workflow run ${run_id}."
                echo '```'
                echo ""
              } >> "$failure_summary_file"
              update_pr_description
              return
            fi

            local failed_count=$(jq '[.jobs[] | select(.conclusion == "failure")] | length' \
              /tmp/jobs_${run_id}.json)
            echo "Failed jobs: $failed_count"
            echo ""
            
            # Add to failure summary for PR description
            {
              echo ""
              echo "### ‚ùå $workflow_name"
              echo ""
            } >> "$failure_summary_file"

            # Process each failed job
            jq -r '.jobs[] | select(.conclusion == "failure") | "\(.id)|\(.name)"' \
              /tmp/jobs_${run_id}.json | \
            while IFS='|' read -r job_id job_name; do
              echo "--- Failed Job: $job_name ---"

              # Get job logs
              if gh api "/repos/${{ github.repository }}/actions/jobs/${job_id}/logs" \
                > /tmp/log_${job_id}.txt 2>&1; then
                # Extract relevant failure text
                failure_text=$(extract_failed_step "/tmp/log_${job_id}.txt" "$job_name" "$workflow_name")
                echo "$failure_text"
                echo ""
                
                # Add to PR description summary
                {
                  echo '```'
                  echo "$failure_text"
                  echo '```'
                  echo ""
                } >> "$failure_summary_file"
                
                # Update PR description after each job (not after all jobs)
                update_pr_description
              else
                echo "‚ö†Ô∏è Could not download logs"
                echo ""
                {
                  echo '```'
                  echo "Unable to download logs for job: $job_name"
                  echo '```'
                  echo ""
                } >> "$failure_summary_file"
                update_pr_description
              fi

              rm -f /tmp/log_${job_id}.txt
            done

            rm -f /tmp/jobs_${run_id}.json
            echo ""
          }

          # Poll for workflow completions and individual job completions
          poll_count=0
          max_polls=720  # 720 * 5s = 1 hour max
          completed_count=0
          
          # Track reported jobs (separate from reported workflow runs)
          mkdir -p /tmp/reported_jobs
          
          # Initial PR description update to show tests are starting
          echo "Setting initial PR description status..."
          update_pr_description

          while [ $poll_count -lt $max_polls ]; do
            poll_count=$((poll_count + 1))

            # Get workflow runs for this commit
            runs_json=$(gh api \
              "/repos/${{ github.repository }}/actions/runs?head_sha=${COMMIT_SHA}&per_page=100")

            # Process each monitored workflow
            for workflow_name in "${workflows[@]}"; do
              # Find the latest run for this workflow
              run_info=$(echo "$runs_json" | jq -r --arg name "$workflow_name" \
                '[.workflow_runs[] | select(.name == $name)] | sort_by(.run_number) | reverse | .[0] | "\(.id)|\(.conclusion)|\(.status)"' \
                | head -1)

              if [ -z "$run_info" ]; then
                continue
              fi

              IFS='|' read -r run_id conclusion status <<< "$run_info"

              # For "Unit tests" workflow, process individual jobs as they complete
              # This gives us one-by-one job reporting instead of all-at-once
              if [ "$workflow_name" = "Unit tests" ]; then
                # Get jobs for this run
                if gh api "/repos/${{ github.repository }}/actions/runs/${run_id}/jobs" \
                  > /tmp/unit_jobs_${run_id}.json 2>&1; then
                  
                  # Process each job individually
                  jq -r '.jobs[] | select(.conclusion != null) | "\(.id)|\(.name)|\(.conclusion)"' \
                    /tmp/unit_jobs_${run_id}.json | \
                  while IFS='|' read -r job_id job_name job_conclusion; do
                    # Skip if already reported
                    if [ -f "/tmp/reported_jobs/$job_id" ]; then
                      continue
                    fi
                    
                    touch "/tmp/reported_jobs/$job_id"
                    
                    echo "----------------------------------------"
                    echo "Unit Test Job: $job_name"
                    echo "Job ID: $job_id"
                    echo "Status: $job_conclusion"
                    echo ""
                    
                    if [ "$job_conclusion" = "success" ]; then
                      echo "‚úÖ Passed"
                      echo ""
                      continue
                    fi
                    
                    if [ "$job_conclusion" != "failure" ]; then
                      echo "Status: $job_conclusion (skipped)"
                      echo ""
                      continue
                    fi
                    
                    echo "‚ùå FAILED - extracting error details..."
                    echo ""
                    
                    # Get job logs and extract failure
                    if gh api "/repos/${{ github.repository }}/actions/jobs/${job_id}/logs" \
                      > /tmp/log_${job_id}.txt 2>&1; then
                      failure_text=$(extract_failed_step "/tmp/log_${job_id}.txt" "$job_name" "$workflow_name")
                      echo "$failure_text"
                      echo ""
                      
                      # Add to PR description summary - use single-level heading
                      {
                        echo ""
                        echo "### ‚ùå Unit tests - $job_name"
                        echo '```'
                        echo "$failure_text"
                        echo '```'
                        echo ""
                      } >> "$failure_summary_file"
                      
                      # Update PR description immediately after each job
                      update_pr_description
                    else
                      echo "‚ö†Ô∏è Could not download logs"
                      echo ""
                    fi
                    
                    rm -f /tmp/log_${job_id}.txt
                  done
                  
                  rm -f /tmp/unit_jobs_${run_id}.json
                fi
                
                # Only mark workflow as complete when all jobs are done
                if [ "$status" = "completed" ]; then
                  if [ ! -f "/tmp/reported_runs/$run_id" ]; then
                    touch "/tmp/reported_runs/$run_id"
                    echo "‚úÖ Unit tests workflow completed"
                  fi
                fi
              else
                # For other workflows, process normally (all jobs at once when workflow completes)
                if [ "$status" = "completed" ]; then
                  process_workflow_run "$run_id" "$workflow_name" "$conclusion"
                fi
              fi
            done

            # Count how many are completed
            completed_count=$(ls -1 /tmp/reported_runs 2>/dev/null | wc -l)

            # Check if all workflows are completed
            if [ "$completed_count" -ge "${#workflows[@]}" ]; then
              echo "All workflows completed. Monitoring finished."
              break
            fi

            # Log progress every minute (12 polls)
            if [ $((poll_count % 12)) -eq 0 ]; then
              echo "[$(date -u +%H:%M:%S)] Monitoring... ($completed_count/${#workflows[@]} workflows completed)"
            fi

            # Sleep before next poll
            sleep 5
          done

          if [ $poll_count -ge $max_polls ]; then
            echo "‚ö†Ô∏è Monitoring timeout reached (1 hour)"
          fi

          echo ""
          echo "========================================================================"
          echo " WORKFLOW FAILURE COLLECTION - Complete"
          echo "========================================================================"
          
          # Set output for final PR description update
          if [ -s "$failure_summary_file" ]; then
            echo "has_failures=true" >> "$GITHUB_OUTPUT"
            # Encode failure summary for output (escape newlines and quotes)
            {
              echo "failure_summary<<EOF"
              cat "$failure_summary_file"
              echo "EOF"
            } >> "$GITHUB_OUTPUT"
            {
              echo "success_summary<<EOF"
              cat "$success_summary_file"
              echo "EOF"
            } >> "$GITHUB_OUTPUT"

            # Exit with failure status so this workflow fails when tests fail
            echo "‚ùå Some workflows failed"
            exit 1
          else
            echo "has_failures=false" >> "$GITHUB_OUTPUT"
            echo "failure_summary=" >> "$GITHUB_OUTPUT"
            {
              echo "success_summary<<EOF"
              cat "$success_summary_file"
              echo "EOF"
            } >> "$GITHUB_OUTPUT"
            echo "‚úÖ All workflows succeeded"
          fi

      - name: Create summary
        if: always()
        run: |
          {
            echo "# üîç Test Failure Collection"
            echo ""
            echo "**PR:** #${{ github.event.pull_request.number }}"
            echo "**Commit:** ${{ github.event.pull_request.head.sha }}"
            echo ""
            echo "This workflow monitors all test workflows for this PR and reports failures."
            echo ""
            echo "Failures are added to the PR description in the '## üîç Latest Test Failures' section."
            echo "AI agents can read them by running: \`./.github/read-test-failures ${{ github.event.pull_request.number }}\`"
            echo ""
            echo "See the workflow logs above for detailed failure information."
          } >> "$GITHUB_STEP_SUMMARY"
      
      - name: Update PR description
        if: always()
        uses: actions/github-script@v7
        env:
          HAS_FAILURES: ${{ steps.collect.outputs.has_failures }}
          FAILURE_SUMMARY: ${{ steps.collect.outputs.failure_summary }}
          SUCCESS_SUMMARY: ${{ steps.collect.outputs.success_summary }}
        with:
          script: |
            const pr = ${{ github.event.pull_request.number }};
            const hasFailures = process.env.HAS_FAILURES === 'true';
            const failureSummary = process.env.FAILURE_SUMMARY || '';
            const successSummary = process.env.SUCCESS_SUMMARY || '';
            const runId = '${{ github.run_id }}';
            const date = new Date().toISOString().split('T')[0];
            const time = new Date().toISOString().split('T')[1].slice(0,8);
            
            console.log('Updating PR #' + pr);
            console.log('Has failures:', hasFailures);
            console.log('Failure summary length:', failureSummary.length);
            
            // Get current PR
            const { data: pullRequest } = await github.rest.pulls.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: pr
            });
            
            let currentBody = pullRequest.body || '';
            
            // Check if the intermediate updates already set a status message
            // If the body contains "Tests are running" or "Tests are still running", 
            // the bash script already updated it, so we should NOT overwrite
            const hasRunningMessage = currentBody.includes('‚è≥ Tests are running') || 
                                       currentBody.includes('‚ö†Ô∏è Tests are still running');
            
            // Create failure section
            let failureSection;
            if (hasFailures && failureSummary) {
              failureSection = [
                '',
                '---',
                '',
                '## üîç Latest Test Failures',
                '',
                '**Updated:** ' + date + ' ' + time + ' UTC',
                '',
                failureSummary,
                '',
                '## ‚úÖ Latest Test Successes',
                '',
                successSummary ? successSummary : '_No successful workflows recorded yet._',
                '',
                'üí° **View detailed logs:** Check the [workflow run logs](../../actions/runs/' + runId + ')',
                '',
                '<!-- test-failures-end -->'
              ].join('\n');
            } else if (hasRunningMessage) {
              // Don't overwrite if tests are still running
              console.log('Tests still running, keeping existing status message');
              return;
            } else {
              failureSection = [
                '',
                '---',
                '',
                '## üîç Latest Test Failures',
                '',
                '**Updated:** ' + date + ' ' + time + ' UTC',
                '',
                successSummary ? successSummary : '‚úÖ All tests passing!',
                successSummary ? '' : '',
                '## ‚úÖ Latest Test Successes',
                '',
                successSummary ? successSummary : '_No successful workflows recorded yet._',
                '',
                '<!-- test-failures-end -->'
              ].join('\n');
            }
            
            // Remove existing failure section if present
            const failureStart = currentBody.indexOf('## üîç Latest Test Failures');
            if (failureStart !== -1) {
              const failureEnd = currentBody.indexOf('<!-- test-failures-end -->');
              if (failureEnd !== -1) {
                // Remove from start of section to end marker (including preceding ---)
                let startPos = failureStart;
                // Look back for the --- separator
                const dashesPos = currentBody.lastIndexOf('---', failureStart);
                if (dashesPos !== -1 && dashesPos > failureStart - 20) {
                  startPos = dashesPos;
                }
                const beforeSection = currentBody.substring(0, startPos);
                const afterSection = currentBody.substring(failureEnd + 28); // +28 for <!-- test-failures-end -->
                currentBody = beforeSection + afterSection;
              }
            }
            
            // Append new failure section
            const newBody = currentBody.trim() + failureSection;
            
            console.log('Updating PR body, new length:', newBody.length);
            
            // Update PR body
            try {
              await github.rest.pulls.update({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: pr,
                body: newBody
              });
              console.log('‚úÖ PR description updated successfully');
            } catch (error) {
              console.error('‚ùå Failed to update PR description:', error.message);
              throw error;
            }
